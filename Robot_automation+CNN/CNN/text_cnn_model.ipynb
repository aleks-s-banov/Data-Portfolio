{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0958036e",
   "metadata": {},
   "source": [
    "# Binary text classification with a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374f33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all our imports\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "# importing the two csv\n",
    "csv1 = pd.read_csv(\"data/elonmusk_tweets.csv\")\n",
    "csv2 = pd.read_csv(\"data/trump_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea627c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849636868052275200</td>\n",
       "      <td>2017-04-05T14:56:29</td>\n",
       "      <td>b'And so the robots spared humanity ... https://t.co/v7JUJQWfCv'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848988730585096192</td>\n",
       "      <td>2017-04-03T20:01:01</td>\n",
       "      <td>b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exactly. Tesla is absurdly overvalued if based on the past, but that's irr\\xe2\\x80\\xa6 https://t.co/qQcTqkzgMl\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848943072423497728</td>\n",
       "      <td>2017-04-03T16:59:35</td>\n",
       "      <td>b'@waltmossberg @mims @defcon_5 Et tu, Walt?'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>848935705057280001</td>\n",
       "      <td>2017-04-03T16:30:19</td>\n",
       "      <td>b'Stormy weather in Shortville ...'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848416049573658624</td>\n",
       "      <td>2017-04-02T06:05:23</td>\n",
       "      <td>b\"@DaveLeeBBC @verge Coal is dying due to nat gas fracking. It's basically dead.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>142881284019060736</td>\n",
       "      <td>2011-12-03T08:22:07</td>\n",
       "      <td>b'That was a total non sequitur btw'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>142880871391838208</td>\n",
       "      <td>2011-12-03T08:20:28</td>\n",
       "      <td>b'Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>142188458125963264</td>\n",
       "      <td>2011-12-01T10:29:04</td>\n",
       "      <td>b'I made the volume on the Model S http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge...'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>142179928203460608</td>\n",
       "      <td>2011-12-01T09:55:11</td>\n",
       "      <td>b\"Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :) http://t.co/rBQXJ9IT\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>15434727182</td>\n",
       "      <td>2010-06-04T18:31:57</td>\n",
       "      <td>b'Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2819 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id           created_at  \\\n",
       "0     849636868052275200  2017-04-05T14:56:29   \n",
       "1     848988730585096192  2017-04-03T20:01:01   \n",
       "2     848943072423497728  2017-04-03T16:59:35   \n",
       "3     848935705057280001  2017-04-03T16:30:19   \n",
       "4     848416049573658624  2017-04-02T06:05:23   \n",
       "...                  ...                  ...   \n",
       "2814  142881284019060736  2011-12-03T08:22:07   \n",
       "2815  142880871391838208  2011-12-03T08:20:28   \n",
       "2816  142188458125963264  2011-12-01T10:29:04   \n",
       "2817  142179928203460608  2011-12-01T09:55:11   \n",
       "2818         15434727182  2010-06-04T18:31:57   \n",
       "\n",
       "                                                                                                                                                            text  \n",
       "0                                                                                               b'And so the robots spared humanity ... https://t.co/v7JUJQWfCv'  \n",
       "1     b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exactly. Tesla is absurdly overvalued if based on the past, but that's irr\\xe2\\x80\\xa6 https://t.co/qQcTqkzgMl\"  \n",
       "2                                                                                                                  b'@waltmossberg @mims @defcon_5 Et tu, Walt?'  \n",
       "3                                                                                                                            b'Stormy weather in Shortville ...'  \n",
       "4                                                                              b\"@DaveLeeBBC @verge Coal is dying due to nat gas fracking. It's basically dead.\"  \n",
       "...                                                                                                                                                          ...  \n",
       "2814                                                                                                                        b'That was a total non sequitur btw'  \n",
       "2815                 b'Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.'  \n",
       "2816                                    b'I made the volume on the Model S http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge...'  \n",
       "2817             b\"Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :) http://t.co/rBQXJ9IT\"  \n",
       "2818                                                             b'Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.'  \n",
       "\n",
       "[2819 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the defalt column with to take a better look at the text data\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "csv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193c3f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\AppData\\Local\\Temp\\ipykernel_2136\\3275627726.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv1['text'] = csv1['text'].str[2:]\n",
      "C:\\Users\\aleks\\AppData\\Local\\Temp\\ipykernel_2136\\3275627726.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv1['text'] = csv1['text'].apply(split_it)\n"
     ]
    }
   ],
   "source": [
    "# some light preprocessing\n",
    "csv1['id']= 'Trump'\n",
    "csv1=csv1[['id','text']]\n",
    "csv1['text'] = csv1['text'].str[2:]\n",
    "\n",
    "# a function which removes the hyperlinks and the usernames of the featured twitter users\n",
    "def split_it(string):\n",
    "    result = re.sub(r'https?://\\S+', '', string)\n",
    "    result1 = re.sub(r'@\\S+','',result)\n",
    "    return result1\n",
    "\n",
    "csv1['text'] = csv1['text'].apply(split_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8cef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>763398630812311552</td>\n",
       "      <td>Morning Joe's weakness is its low ratings. I don't watch anymore but I heard he went wild against Rudy Giuliani and #2A - sad &amp;amp; irrelevant!</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>763391459110313984</td>\n",
       "      <td>.@dbongino  You were fantastic in defending both the Second Amendment and me last night on @CNN. Don Lemon is a lightweight - dumb as a rock</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>763385288295055360</td>\n",
       "      <td>\"@dbongino: ‘Now cut off my mic!’ Bongino refuses to be bullied by Don Lemon over Trump, 2nd Amendment – HEATED! https://t.co/UgtfaUXzcr\"</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>763198483927011329</td>\n",
       "      <td>Media desperate to distract from Clinton's anti-2A stance. I said pro-2A citizens must organize and get out vote to save our Constitution!</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>763180978588221440</td>\n",
       "      <td>When is the media going to talk about Hillary's policies that have gotten people killed, like Libya, open borders, and maybe her emails?</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>702155147695284224</td>\n",
       "      <td>\"@Vogelsong1: @EdRollins gets it. Was just on @FoxNews explaining how Trump wins the general election.\"  Thank you Ed!</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>702149896325890048</td>\n",
       "      <td>Ted Cruz lifts the Bible high into the air and then lies like a dog-over and over again! The Evangelicals in S.C. figured him out &amp;amp; said no!</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>702147760926011393</td>\n",
       "      <td>Ted Cruz does not have the right \"temperment\" to be President. Look at the way he totally panicked in firing his director of comm. BAD!</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>702141081027104769</td>\n",
       "      <td>Wow was Ted Cruz disloyal to his very capable director of communication. He used him as a scape goat-fired like a dog! Ted panicked.</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>702140146343280640</td>\n",
       "      <td>Ted Cruz only talks tough on immigration now because he did so badly in S.C. He is in favor of amnesty and weak on illegal immigration.</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1927 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0     763398630812311552   \n",
       "1     763391459110313984   \n",
       "2     763385288295055360   \n",
       "3     763198483927011329   \n",
       "4     763180978588221440   \n",
       "...                  ...   \n",
       "1922  702155147695284224   \n",
       "1923  702149896325890048   \n",
       "1924  702147760926011393   \n",
       "1925  702141081027104769   \n",
       "1926  702140146343280640   \n",
       "\n",
       "                                                                                                                                                  text  \\\n",
       "0      Morning Joe's weakness is its low ratings. I don't watch anymore but I heard he went wild against Rudy Giuliani and #2A - sad &amp; irrelevant!   \n",
       "1         .@dbongino  You were fantastic in defending both the Second Amendment and me last night on @CNN. Don Lemon is a lightweight - dumb as a rock   \n",
       "2            \"@dbongino: ‘Now cut off my mic!’ Bongino refuses to be bullied by Don Lemon over Trump, 2nd Amendment – HEATED! https://t.co/UgtfaUXzcr\"   \n",
       "3           Media desperate to distract from Clinton's anti-2A stance. I said pro-2A citizens must organize and get out vote to save our Constitution!   \n",
       "4             When is the media going to talk about Hillary's policies that have gotten people killed, like Libya, open borders, and maybe her emails?   \n",
       "...                                                                                                                                                ...   \n",
       "1922                            \"@Vogelsong1: @EdRollins gets it. Was just on @FoxNews explaining how Trump wins the general election.\"  Thank you Ed!   \n",
       "1923  Ted Cruz lifts the Bible high into the air and then lies like a dog-over and over again! The Evangelicals in S.C. figured him out &amp; said no!   \n",
       "1924           Ted Cruz does not have the right \"temperment\" to be President. Look at the way he totally panicked in firing his director of comm. BAD!   \n",
       "1925              Wow was Ted Cruz disloyal to his very capable director of communication. He used him as a scape goat-fired like a dog! Ted panicked.   \n",
       "1926           Ted Cruz only talks tough on immigration now because he did so badly in S.C. He is in favor of amnesty and weak on illegal immigration.   \n",
       "\n",
       "                   source  \n",
       "0      Twitter for iPhone  \n",
       "1     Twitter for Android  \n",
       "2     Twitter for Android  \n",
       "3      Twitter for iPhone  \n",
       "4      Twitter Web Client  \n",
       "...                   ...  \n",
       "1922  Twitter for Android  \n",
       "1923  Twitter for Android  \n",
       "1924  Twitter for Android  \n",
       "1925  Twitter for Android  \n",
       "1926  Twitter for Android  \n",
       "\n",
       "[1927 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ee85df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\AppData\\Local\\Temp\\ipykernel_2136\\2233951345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv2['text'] = csv2['text'].apply(split_it)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon</td>\n",
       "      <td>Morning Joe's weakness is its low ratings. I don't watch anymore but I heard he went wild against Rudy Giuliani and #2A - sad &amp;amp; irrelevant!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elon</td>\n",
       "      <td>.  You were fantastic in defending both the Second Amendment and me last night on  Don Lemon is a lightweight - dumb as a rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elon</td>\n",
       "      <td>\" ‘Now cut off my mic!’ Bongino refuses to be bullied by Don Lemon over Trump, 2nd Amendment – HEATED!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elon</td>\n",
       "      <td>Media desperate to distract from Clinton's anti-2A stance. I said pro-2A citizens must organize and get out vote to save our Constitution!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elon</td>\n",
       "      <td>When is the media going to talk about Hillary's policies that have gotten people killed, like Libya, open borders, and maybe her emails?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>Elon</td>\n",
       "      <td>\"  gets it. Was just on  explaining how Trump wins the general election.\"  Thank you Ed!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>Elon</td>\n",
       "      <td>Ted Cruz lifts the Bible high into the air and then lies like a dog-over and over again! The Evangelicals in S.C. figured him out &amp;amp; said no!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>Elon</td>\n",
       "      <td>Ted Cruz does not have the right \"temperment\" to be President. Look at the way he totally panicked in firing his director of comm. BAD!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>Elon</td>\n",
       "      <td>Wow was Ted Cruz disloyal to his very capable director of communication. He used him as a scape goat-fired like a dog! Ted panicked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>Elon</td>\n",
       "      <td>Ted Cruz only talks tough on immigration now because he did so badly in S.C. He is in favor of amnesty and weak on illegal immigration.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1927 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0     Elon   \n",
       "1     Elon   \n",
       "2     Elon   \n",
       "3     Elon   \n",
       "4     Elon   \n",
       "...    ...   \n",
       "1922  Elon   \n",
       "1923  Elon   \n",
       "1924  Elon   \n",
       "1925  Elon   \n",
       "1926  Elon   \n",
       "\n",
       "                                                                                                                                                  text  \n",
       "0      Morning Joe's weakness is its low ratings. I don't watch anymore but I heard he went wild against Rudy Giuliani and #2A - sad &amp; irrelevant!  \n",
       "1                       .  You were fantastic in defending both the Second Amendment and me last night on  Don Lemon is a lightweight - dumb as a rock  \n",
       "2                                              \" ‘Now cut off my mic!’ Bongino refuses to be bullied by Don Lemon over Trump, 2nd Amendment – HEATED!   \n",
       "3           Media desperate to distract from Clinton's anti-2A stance. I said pro-2A citizens must organize and get out vote to save our Constitution!  \n",
       "4             When is the media going to talk about Hillary's policies that have gotten people killed, like Libya, open borders, and maybe her emails?  \n",
       "...                                                                                                                                                ...  \n",
       "1922                                                          \"  gets it. Was just on  explaining how Trump wins the general election.\"  Thank you Ed!  \n",
       "1923  Ted Cruz lifts the Bible high into the air and then lies like a dog-over and over again! The Evangelicals in S.C. figured him out &amp; said no!  \n",
       "1924           Ted Cruz does not have the right \"temperment\" to be President. Look at the way he totally panicked in firing his director of comm. BAD!  \n",
       "1925              Wow was Ted Cruz disloyal to his very capable director of communication. He used him as a scape goat-fired like a dog! Ted panicked.  \n",
       "1926           Ted Cruz only talks tough on immigration now because he did so badly in S.C. He is in favor of amnesty and weak on illegal immigration.  \n",
       "\n",
       "[1927 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same light preprocessing for the elon data\n",
    "csv2['id']= 'Elon'\n",
    "csv2=csv2[['id','text']]\n",
    "\n",
    "# same function which removes the hyperlinks and the usernames of the featured twitter users\n",
    "def split_it(string):\n",
    "    result = re.sub(r'https?://\\S+', '', string)\n",
    "    result1 = re.sub(r'@\\S+','',result)\n",
    "    return result1\n",
    "\n",
    "csv2['text'] = csv2['text'].apply(split_it)\n",
    "csv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f9f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we concatenate both dataframes and change the label variable to binary \n",
    "concate_data = pd.concat([csv1,csv2])\n",
    "\n",
    "concate_data.head()\n",
    "concate_data[\"id\"] = concate_data[\"id\"].map({'Trump' : 1, 'Elon' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69edc5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>And so the robots spared humanity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Exactly. Tesla is absurdly overvalued if based on the past, but that's irr\\xe2\\x80\\xa6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Et tu, Walt?'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Stormy weather in Shortville ...'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Coal is dying due to nat gas fracking. It's basically dead.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   1   \n",
       "2   1   \n",
       "3   1   \n",
       "4   1   \n",
       "\n",
       "                                                                                          text  \n",
       "0                                                       And so the robots spared humanity ...   \n",
       "1      Exactly. Tesla is absurdly overvalued if based on the past, but that's irr\\xe2\\x80\\xa6   \n",
       "2                                                                                Et tu, Walt?'  \n",
       "3                                                            Stormy weather in Shortville ...'  \n",
       "4                                 Coal is dying due to nat gas fracking. It's basically dead.\"  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6635794",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = concate_data['text'].values\n",
    "label = concate_data['id'].values\n",
    "\n",
    "# splitting the data 25% test size\n",
    "review_train, review_test, label_train, label_test = train_test_split(review, label, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e32d797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flying car pros: travel in 3D fast. Cons: risk of car falling on head much greater, noisy, grounded in bad weather'\n",
      "[659, 92, 991, 5, 505, 506, 4, 92, 9, 803, 94, 5, 103]\n"
     ]
    }
   ],
   "source": [
    "# Here we use Tokenizer which allows us to vectorize a text corpus\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(review_train)\n",
    "Xcnn_train = tokenizer.texts_to_sequences(review_train)\n",
    "Xcnn_test = tokenizer.texts_to_sequences(review_test)\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "print(review_train[1])\n",
    "print(Xcnn_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa5841e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132 303   1 142 143   2 614  16   9   1 256  98  88  55  35   7  11 168\n",
      "  52 359 360   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Each sequence is the different length of words, we use pad_sequences(), which pads the sequence of words with zeros.\n",
    "max_lenth = 50\n",
    "\n",
    "Xcnn_train = pad_sequences(Xcnn_train, padding='post', maxlen=max_lenth)\n",
    "Xcnn_test = pad_sequences(Xcnn_test, padding='post', maxlen=max_lenth)\n",
    "print(Xcnn_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "730e2c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 200)           1506000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 46, 128)           128128    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,635,429\n",
      "Trainable params: 1,635,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We make the models using layers in it.\n",
    "# We use 200 dimentions and add my own embeddings, other pre-trained embeddings could be used the most popular one are the GloVe embeddings.\n",
    "embedding_dim = 200\n",
    "model= Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=max_lenth))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd22f243",
   "metadata": {},
   "source": [
    "Unlike image processing text classification is not the primary use of the convolutional neural network but it still works great if we use a 1 dimentional one. Even other stuff like MaxPooling is still applicable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f239c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9975\n",
      "Testing Accuracy:  0.9478\n"
     ]
    }
   ],
   "source": [
    "# Here I fit the model and test the accuracy\n",
    "model.fit(Xcnn_train, label_train,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                    validation_data=(Xcnn_test, label_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(Xcnn_train, label_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(Xcnn_test, label_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689cf0a",
   "metadata": {},
   "source": [
    "Hmm quite a nice result. Either we didn't do enough preprocessing and there're parts of the tweets have great predictive power or our model is just that awsome!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
